# -*- coding: utf-8 -*-
"""Assignment1_CS771.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pDxgl5TdxGijKxOx2HgGwkhBLJYNmFI9
"""

import numpy as np


# You are not allowed to use any ML libraries e.g. sklearn, scipy, keras, tensorflow etc

# SUBMIT YOUR CODE AS A SINGLE PYTHON (.PY) FILE INSIDE A ZIP ARCHIVE
# THE NAME OF THE PYTHON FILE MUST BE submit.py
# DO NOT INCLUDE OTHER PACKAGES LIKE SKLEARN, SCIPY, KERAS,TENSORFLOW ETC IN YOUR CODE
# THE USE OF ANY MACHINE LEARNING LIBRARIES WILL RESULT IN A STRAIGHT ZERO

# DO NOT CHANGE THE NAME OF THE METHOD my_fit BELOW
# THESE WILL BE INVOKED BY THE EVALUATION SCRIPT. CHANGING THESE NAMES WILL CAUSE EVALUATION FAILURE


def HT(v, k):
    t = np.zeros_like(v)
    if k < 1:
        return t
    else:
        ind = np.argsort(abs(v))[-k:]
        t[ind] = v[ind]
        return t


def predict(X_trn, model):
    return X_trn.dot(model)


def calculate_mae(X_trn, y_trn, model):
    predictions = predict(X_trn, model)
    mae = np.mean(np.abs(predictions - y_trn))
    return mae


################################
# Non Editable Region Starting #
################################
def my_fit(X_trn, y_trn):
    ################################
    #  Non Editable Region Ending  #
    ################################

    iter = 0

    # Projection gradient method

    N, D = X_trn.shape  # N=no.of data samples ,D=no.of features
    model = np.zeros(D)  # initialise w to zero
    neta = 1e-3  # learning rate (reduced further)
    # lamda=1 #thresold
    tolerance = 1e-4
    maxiter = 1000
    S = 512
    while (iter < maxiter):
        # calculate gradient of loss function
        gradient = (1 / N) * (X_trn.T.dot(X_trn.dot(model) - y_trn))
        model_new = model - neta * gradient
        # # apply soft thresholding
        # model=ST(model_new,lamda)
        # apply hard thresholding
        # Apply hard thresholding to keep the iterates sparse
        model = HT(model_new, S)
        # apply convergence
        if np.linalg.norm(model - model_new) < tolerance:
            break
        model = model_new
        iter = iter + 1

    # Use this method to train your model using training CRPs
    # Your method should return a 2048-dimensional vector that is 512-sparse
    # No bias term allowed -- return just a single 2048-dim vector as output
    # If the vector you return is not 512-sparse, it will be sparsified using hard-thresholding
    return model  # Return the trained model


X = np.loadtxt('/train_challenges.dat')
Y = np.loadtxt('/train_responses.dat')
w = my_fit(X, Y)

# Calculate the mean absolute error
mae = calculate_mae(X, Y, w)
print("Mean Absolute Error (MAE):", mae)

import time

start_time = time.time()
w = my_fit(X, Y)
end_time = time.time()
train_time = end_time - start_time

print("Training Time:", train_time, "seconds")



